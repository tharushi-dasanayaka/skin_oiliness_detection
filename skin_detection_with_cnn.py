# -*- coding: utf-8 -*-
"""Skin_detection_with_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z3Jh6OJrSkU_Pv68hGeJ_hE3jgbmUmKP
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install tensorflow
!pip install numpy!pip install scikit-learn

import tensorflow as tf
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

import os
import shutil
import random

# Define paths
original_data_path = '/content/drive/My Drive'
output_data_path = '/content/drive/My Drive/Skin Detection Using CNN'

# Define ratios for splitting
train_ratio = 0.8

test_ratio = 0.2

# Create directories for train, validation, and test sets
train_path = os.path.join(output_data_path, 'train')

test_path = os.path.join(output_data_path, 'test')

os.makedirs(train_path, exist_ok=True)

os.makedirs(test_path, exist_ok=True)

# List classes
classes = ['Oily', 'Dry', 'Normal']

# Iterate through classes
for class_name in classes:
    # Get list of files in current class
    class_files = os.listdir(os.path.join(original_data_path, 'Skin Detection Using CNN', class_name))
    # Shuffle files
    random.shuffle(class_files)

    # Split files into train, val, and test sets
    num_files = len(class_files)
    num_train = int(num_files * train_ratio)
    num_test = int(num_files * test_ratio)


    # Copy files to respective directories
    for i, file_name in enumerate(class_files):
        src = os.path.join(original_data_path, 'Skin Detection Using CNN', class_name, file_name)
        if i < num_train:
            dst = os.path.join(train_path, class_name, file_name)

        else:
            dst = os.path.join(test_path, class_name, file_name)

        # Create directories if they don't exist
        os.makedirs(os.path.dirname(dst), exist_ok=True)
        # Copy file
        shutil.copy(src, dst)

print("Data splitting and copying completed successfully.")

import os
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator

def augment_images(class_directory, output_directory):
    # Create the output directory if it doesn't exist
    os.makedirs(output_directory, exist_ok=True)

    # Define augmentation parameters
    datagen = ImageDataGenerator(
        rotation_range=20,      # Randomly rotate images by up to 20 degrees
        width_shift_range=0.1,  # Randomly shift images horizontally by up to 10% of the width
        height_shift_range=0.1, # Randomly shift images vertically by up to 10% of the height
        horizontal_flip=True    # Randomly flip images horizontally
    )

    # List all images in the class directory
    image_files = [file for file in os.listdir(class_directory) if file.lower().endswith(('.png', '.jpg', '.jpeg'))]

    # Augment each image and save the augmented images
    for image_file in image_files:
        image_path = os.path.join(class_directory, image_file)
        img = image.load_img(image_path, target_size=(224, 224))
        x = image.img_to_array(img)
        x = x.reshape((1,) + x.shape)  # Reshape to (1, height, width, channels)

        # Generate augmented images and save them directly into the output directory
        i = 0
        for batch in datagen.flow(x, batch_size=1, save_to_dir=output_directory, save_prefix='augmented_' + image_file.split('.')[0], save_format='jpg'):
            i += 1
            if i >= 3:  # Generate 3 augmented images per original image
                break

# Define paths for Dry class
train_path_dry = '/content/drive/My Drive/Skin Detection Using CNN/train/Dry'
output_augmented_path_dry = '/content/drive/My Drive/Skin Detection Using CNN/train/Dry'

# Define paths for Oily class
train_path_oily = '/content/drive/My Drive/Skin Detection Using CNN/train/Oily'
output_augmented_path_oily = '/content/drive/My Drive/Skin Detection Using CNN/train/Oily'

# Define paths for Normal class
train_path_normal = '/content/drive/My Drive/Skin Detection Using CNN/train/Normal'
output_augmented_path_normal = '/content/drive/My Drive/Skin Detection Using CNN/train/Normal'

# Function to augment images for Dry class
augment_images(train_path_dry, output_augmented_path_dry)

# Function to augment images for Oily class
augment_images(train_path_oily, output_augmented_path_oily)

# Function to augment images for Normal class
augment_images(train_path_normal, output_augmented_path_normal)

import os

# Define the parent directory containing the three class directories
parent_directory = '/content/drive/My Drive/Skin Detection Using CNN/train'

# List of class names
class_names = ['Dry', 'Normal', 'Oily']

# Dictionary to store the counts for each class
class_counts = {}

# Iterate over each class directory
for class_name in class_names:
    # Define the path to the class directory
    class_path = os.path.join(parent_directory, class_name)

    # List all files in the class directory
    files_in_directory = os.listdir(class_path)

    # Count the number of images in the class directory
    num_images = len(files_in_directory)

    # Store the count in the dictionary
    class_counts[class_name] = num_images

# Print the counts for each class
for class_name, count in class_counts.items():
    print("Number of images in '{}' class: {}".format(class_name, count))

import os
import cv2
import numpy as np
from skimage import exposure
from google.colab.patches import cv2_imshow

# Define paths
augmented_data_path = '/content/drive/My Drive/Skin Detection Using CNN/train/'

# Load face detection cascade
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Function to detect faces in an image
def detect_faces(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.1, 4)
    return faces

# Function to reduce noise in the background
def reduce_noise(image, faces):
    for (x,y,w,h) in faces:
        face_region = image[y:y+h, x:x+w]
        blurred_face = cv2.GaussianBlur(face_region, (25,25), 0)
        image[y:y+h, x:x+w] = blurred_face
    return image

# Function to perform preprocessing including rescaling and CLAHE contrast enhancement
def preprocess_image(image):
    # Rescale the image to a desired size (e.g., 256x256)
    resized_image = cv2.resize(image, (256, 256))

    # Convert the image to grayscale
    gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)

    # Apply CLAHE for contrast enhancement
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced_image = clahe.apply(gray_image)

    return enhanced_image

# Iterate over each augmented data folder
for folder_name in os.listdir(augmented_data_path):
    folder_path = os.path.join(augmented_data_path, folder_name)

    # Create a directory to save preprocessed images
    output_folder_path = os.path.join(folder_path, 'preprocessed')
    os.makedirs(output_folder_path, exist_ok=True)

    # Iterate over each image in the folder
    for filename in os.listdir(folder_path):
        if filename.startswith('augmented'):
            image_path = os.path.join(folder_path, filename)
            img = cv2.imread(image_path)

            # Detect faces
            faces = detect_faces(img)

            # Reduce noise in the background
            img_with_noise_reduced = reduce_noise(img, faces)

            # Perform preprocessing
            preprocessed_img = preprocess_image(img_with_noise_reduced)

            # Save the preprocessed image
            output_image_path = os.path.join(output_folder_path, filename)
            cv2.imwrite(output_image_path, preprocessed_img)

import os
import cv2
import numpy as np
from skimage import exposure
from google.colab.patches import cv2_imshow

# Define paths
example_image_path = '/content/drive/My Drive/Skin Detection Using CNN/train/Dry/Dry (14).jpg'

# Load the example image
example_image = cv2.imread(example_image_path)

# Check if the image is loaded successfully
if example_image is None:
    print("Error: Unable to load the example image.")
else:
    # Load face detection cascade
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

    # Function to detect faces in an image
    def detect_faces(image):
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.1, 4)
        return faces

    # Function to reduce noise in the background
    def reduce_noise(image, faces):
        for (x,y,w,h) in faces:
            face_region = image[y:y+h, x:x+w]
            blurred_face = cv2.GaussianBlur(face_region, (25,25), 0)
            image[y:y+h, x:x+w] = blurred_face
        return image

    # Function to perform preprocessing including rescaling and CLAHE contrast enhancement
    def preprocess_image(image):
        # Rescale the image to a desired size (e.g., 256x256)
        resized_image = cv2.resize(image, (256, 256))

        # Convert the image to grayscale
        gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)

        # Apply CLAHE for contrast enhancement
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced_image = clahe.apply(gray_image)

        return enhanced_image

    # Detect faces
    faces = detect_faces(example_image)

    # Reduce noise in the background
    example_image_with_noise_reduced = reduce_noise(example_image, faces)

    # Perform preprocessing
    preprocessed_example_image = preprocess_image(example_image_with_noise_reduced)

    # Convert the preprocessed grayscale image to a three-channel image
    preprocessed_example_image_resized_color = cv2.cvtColor(preprocessed_example_image, cv2.COLOR_GRAY2BGR)

    # Resize the preprocessed image to match the height of the original and noise-reduced images
    preprocessed_example_image_resized_color = cv2.resize(preprocessed_example_image_resized_color, (example_image.shape[1], example_image.shape[0]))

    # Visualize the original, noise-reduced, and preprocessed images
    visualization = np.hstack((example_image, example_image_with_noise_reduced, preprocessed_example_image_resized_color))
    visualization = cv2.resize(visualization, (int(visualization.shape[1] / 2), int(visualization.shape[0] / 2)))
    cv2_imshow(visualization)

import os
import numpy as np
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.utils import to_categorical

# Define the paths to processed image directories
dry_processed_dir = '/content/drive/My Drive/Skin Detection Using CNN/train/Dry/preprocessed'
oily_processed_dir = '/content/drive/My Drive/Skin Detection Using CNN/train/Oily/preprocessed'
normal_processed_dir = '/content/drive/My Drive/Skin Detection Using CNN/train/Normal/preprocessed'

# Function to load processed images from a directory
def load_processed_images(directory):
    images = []
    for filename in os.listdir(directory):
        if filename.endswith(('.jpg', '.png')):
            img = load_img(os.path.join(directory, filename), target_size=(224, 224))
            img_array = img_to_array(img)
            images.append(img_array)
    return np.array(images)

# Load processed images from each class
dry_images = load_processed_images(dry_processed_dir)
oily_images = load_processed_images(oily_processed_dir)
normal_images = load_processed_images(normal_processed_dir)

# Combine images and create labels
X = np.concatenate((dry_images, oily_images, normal_images), axis=0)
y = np.concatenate((np.zeros(len(dry_images)), np.ones(len(oily_images)), np.full(len(normal_images), 2)))

# Shuffle the data
indices = np.arange(X.shape[0])
np.random.shuffle(indices)
X = X[indices]
y = y[indices]

# One-hot encode the target labels
y_one_hot = to_categorical(y)

# Load MobileNetV2 base model
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the base model's layers
base_model.trainable = False

# Create a model using MobileNetV2 as base
model = models.Sequential([
    base_model,
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.MaxPooling2D((2, 2), padding='same'),
    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    layers.MaxPooling2D((2, 2), padding='same'),
    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
    layers.MaxPooling2D((2, 2), padding='same'),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(3, activation='softmax')
])

# Compile the model
model.compile(optimizer='sgd',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Define early stopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Train the model with early stopping
history = model.fit(X, y_one_hot, epochs=8, batch_size=32, validation_split=0.2, callbacks=[early_stopping])

# Save the trained model
model.save('/content/drive/My Drive/Skin Detection Using CNN/mobilenetv2_cnn_model.h1')

# Define paths for testing data
test_data_path = '/content/drive/My Drive/Skin Detection Using CNN/test/'

# Iterate over each class folder in the testing dataset
for class_folder in os.listdir(test_data_path):
    class_folder_path = os.path.join(test_data_path, class_folder)

    # Create a directory to save preprocessed images for each class
    preprocessed_class_folder_path = os.path.join(class_folder_path, 'preprocessed')
    os.makedirs(preprocessed_class_folder_path, exist_ok=True)

    # Iterate over each image in the class folder
    for filename in os.listdir(class_folder_path):
        if filename.endswith(('.jpg', '.jpeg', '.png')):
            image_path = os.path.join(class_folder_path, filename)
            img = cv2.imread(image_path)

            # Detect faces
            faces = detect_faces(img)

            # Reduce noise in the background
            img_with_noise_reduced = reduce_noise(img, faces)

            # Perform preprocessing
            preprocessed_img = preprocess_image(img_with_noise_reduced)

            # Save the preprocessed image
            preprocessed_image_path = os.path.join(preprocessed_class_folder_path, filename)
            cv2.imwrite(preprocessed_image_path, preprocessed_img)

import os
import cv2  # Import OpenCV library
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder

# Load the saved model
saved_model_path = '/content/drive/My Drive/Skin Detection Using CNN/mobilenetv2_cnn_model.h1'
model = load_model(saved_model_path)

# Define the paths to the test image directories
test_dry_dir = '/content/drive/My Drive/Skin Detection Using CNN/test/Dry/preprocessed'
test_oily_dir = '/content/drive/My Drive/Skin Detection Using CNN/test/Oily/preprocessed'
test_normal_dir = '/content/drive/My Drive/Skin Detection Using CNN/test/Normal/preprocessed'

# Function to load and preprocess test images from a directory
def load_and_preprocess_test_images(directory):
    images = []
    labels = []
    label = os.path.basename(directory)  # Extract label from directory name
    for filename in os.listdir(directory):
        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
            img = load_img(os.path.join(directory, filename), target_size=(224, 224))
            img_array = img_to_array(img)
            images.append(img_array)
            labels.append(label)
    return np.array(images), np.array(labels)

# Load and preprocess test images from each class
test_dry_images, test_dry_labels = load_and_preprocess_test_images(test_dry_dir)
test_oily_images, test_oily_labels = load_and_preprocess_test_images(test_oily_dir)
test_normal_images, test_normal_labels = load_and_preprocess_test_images(test_normal_dir)

# Combine test images and labels
test_images = np.concatenate((test_dry_images, test_oily_images, test_normal_images), axis=0)
test_labels = np.concatenate((test_dry_labels, test_oily_labels, test_normal_labels), axis=0)

# Convert labels to numerical format
label_encoder = LabelEncoder()
test_labels_encoded = label_encoder.fit_transform(test_labels)

# Predict labels for test images
y_pred = model.predict(test_images)
y_pred = np.argmax(y_pred, axis=1)

# Calculate evaluation metrics
accuracy = accuracy_score(test_labels_encoded, y_pred)
precision = precision_score(test_labels_encoded, y_pred, average='weighted')
recall = recall_score(test_labels_encoded, y_pred, average='weighted')
f1 = f1_score(test_labels_encoded, y_pred, average='weighted')

print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1-Score: {f1}')

import os
import numpy as np
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Define the paths to processed image directories
dry_processed_dir = '/content/drive/My Drive/Skin Detection Using CNN/train/Dry/preprocessed'
oily_processed_dir = '/content/drive/My Drive/Skin Detection Using CNN/train/Oily/preprocessed'
normal_processed_dir = '/content/drive/My Drive/Skin Detection Using CNN/train/Normal/preprocessed'

# Function to load processed images from a directory
def load_processed_images(directory):
    images = []
    for filename in os.listdir(directory):
        if filename.endswith(('.jpg', '.png')):
            img = load_img(os.path.join(directory, filename), target_size=(224, 224))
            img_array = img_to_array(img)
            images.append(img_array)
    return np.array(images)

# Load processed images from each class
dry_images = load_processed_images(dry_processed_dir)
oily_images = load_processed_images(oily_processed_dir)
normal_images = load_processed_images(normal_processed_dir)

# Combine images and create labels
X = np.concatenate((dry_images, oily_images, normal_images), axis=0)
y = np.concatenate((np.zeros(len(dry_images)), np.ones(len(oily_images)), np.full(len(normal_images), 2)))

# Shuffle the data
indices = np.arange(X.shape[0])
np.random.shuffle(indices)
X = X[indices]
y = y[indices]

# One-hot encode the target labels
y_one_hot = to_categorical(y)

# Load MobileNetV2 base model
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the base model's layers
base_model.trainable = False

# Create a model using MobileNetV2 as base
model = models.Sequential([
    base_model,
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.MaxPooling2D((2, 2), padding='same'),
    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    layers.MaxPooling2D((2, 2), padding='same'),
    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
    layers.MaxPooling2D((2, 2), padding='same'),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(3, activation='softmax')
])

# Compile the model with a lower learning rate
opt = optimizers.SGD(lr=0.001, momentum=0.9)
model.compile(optimizer=opt,
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Define early stopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Train the model with early stopping
history = model.fit(X, y_one_hot, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])

# Save the trained model
model.save('/content/drive/My Drive/Skin Detection Using CNN/mobilenetv2_cnn_model_updated.h2')

import os
import cv2  # Import OpenCV library
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder

# Load the saved model
saved_model_path = '/content/drive/My Drive/Skin Detection Using CNN/mobilenetv2_cnn_model_updated.h2'
model = load_model(saved_model_path)

# Define the paths to the test image directories
test_dry_dir = '/content/drive/My Drive/Skin Detection Using CNN/test/Dry/preprocessed'
test_oily_dir = '/content/drive/My Drive/Skin Detection Using CNN/test/Oily/preprocessed'
test_normal_dir = '/content/drive/My Drive/Skin Detection Using CNN/test/Normal/preprocessed'

# Function to load and preprocess test images from a directory
def load_and_preprocess_test_images(directory):
    images = []
    labels = []
    label = os.path.basename(directory)  # Extract label from directory name
    for filename in os.listdir(directory):
        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
            img = load_img(os.path.join(directory, filename), target_size=(224, 224))
            img_array = img_to_array(img)
            images.append(img_array)
            labels.append(label)
    return np.array(images), np.array(labels)

# Load and preprocess test images from each class
test_dry_images, test_dry_labels = load_and_preprocess_test_images(test_dry_dir)
test_oily_images, test_oily_labels = load_and_preprocess_test_images(test_oily_dir)
test_normal_images, test_normal_labels = load_and_preprocess_test_images(test_normal_dir)

# Combine test images and labels
test_images = np.concatenate((test_dry_images, test_oily_images, test_normal_images), axis=0)
test_labels = np.concatenate((test_dry_labels, test_oily_labels, test_normal_labels), axis=0)

# Convert labels to numerical format
label_encoder = LabelEncoder()
test_labels_encoded = label_encoder.fit_transform(test_labels)

# Predict labels for test images
y_pred = model.predict(test_images)
y_pred = np.argmax(y_pred, axis=1)

# Calculate evaluation metrics
accuracy = accuracy_score(test_labels_encoded, y_pred)
precision = precision_score(test_labels_encoded, y_pred, average='weighted')
recall = recall_score(test_labels_encoded, y_pred, average='weighted')
f1 = f1_score(test_labels_encoded, y_pred, average='weighted')

print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1-Score: {f1}')

import os
import numpy as np
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.utils import to_categorical

# Define the paths to processed image directories
dry_processed_dir = '/content/drive/My Drive/Skin Detection Using CNN/train/Dry/preprocessed'
oily_processed_dir = '/content/drive/My Drive/Skin Detection Using CNN/train/Oily/preprocessed'
normal_processed_dir = '/content/drive/My Drive/Skin Detection Using CNN/train/Normal/preprocessed'

# Function to load processed images from a directory
def load_processed_images(directory):
    images = []
    for filename in os.listdir(directory):
        if filename.endswith(('.jpg', '.png')):
            img = load_img(os.path.join(directory, filename), target_size=(224, 224))
            img_array = img_to_array(img)
            images.append(img_array)
    return np.array(images)

# Load processed images from each class
dry_images = load_processed_images(dry_processed_dir)
oily_images = load_processed_images(oily_processed_dir)
normal_images = load_processed_images(normal_processed_dir)

# Combine images and create labels
X = np.concatenate((dry_images, oily_images, normal_images), axis=0)
y = np.concatenate((np.zeros(len(dry_images)), np.ones(len(oily_images)), np.full(len(normal_images), 2)))

# Shuffle the data
indices = np.arange(X.shape[0])
np.random.shuffle(indices)
X = X[indices]
y = y[indices]

# One-hot encode the target labels
y_one_hot = to_categorical(y)

# Load MobileNetV2 base model
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the base model's layers
base_model.trainable = False

# Create a model using MobileNetV2 as base
model = models.Sequential([
    base_model,
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.MaxPooling2D((2, 2), padding='same'),
    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    layers.MaxPooling2D((2, 2), padding='same'),
    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
    layers.MaxPooling2D((2, 2), padding='same'),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(3, activation='softmax')
])

# Compile the model
model.compile(optimizer='sgd',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Define early stopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Train the model with early stopping
history = model.fit(X, y_one_hot, epochs=15, batch_size=32, validation_split=0.2, callbacks=[early_stopping])

# Save the trained model
model.save('/content/drive/My Drive/Skin Detection Using CNN/mobilenetv2_cnn_model.h3')

import os
import cv2  # Import OpenCV library
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder

# Load the saved model
saved_model_path = '/content/drive/My Drive/Skin Detection Using CNN/mobilenetv2_cnn_model.h3'
model = load_model(saved_model_path)

# Define the paths to the test image directories
test_dry_dir = '/content/drive/My Drive/Skin Detection Using CNN/test/Dry/preprocessed'
test_oily_dir = '/content/drive/My Drive/Skin Detection Using CNN/test/Oily/preprocessed'
test_normal_dir = '/content/drive/My Drive/Skin Detection Using CNN/test/Normal/preprocessed'

# Function to load and preprocess test images from a directory
def load_and_preprocess_test_images(directory):
    images = []
    labels = []
    label = os.path.basename(directory)  # Extract label from directory name
    for filename in os.listdir(directory):
        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
            img = load_img(os.path.join(directory, filename), target_size=(224, 224))
            img_array = img_to_array(img)
            images.append(img_array)
            labels.append(label)
    return np.array(images), np.array(labels)

# Load and preprocess test images from each class
test_dry_images, test_dry_labels = load_and_preprocess_test_images(test_dry_dir)
test_oily_images, test_oily_labels = load_and_preprocess_test_images(test_oily_dir)
test_normal_images, test_normal_labels = load_and_preprocess_test_images(test_normal_dir)

# Combine test images and labels
test_images = np.concatenate((test_dry_images, test_oily_images, test_normal_images), axis=0)
test_labels = np.concatenate((test_dry_labels, test_oily_labels, test_normal_labels), axis=0)

# Convert labels to numerical format
label_encoder = LabelEncoder()
test_labels_encoded = label_encoder.fit_transform(test_labels)

# Predict labels for test images
y_pred = model.predict(test_images)
y_pred = np.argmax(y_pred, axis=1)

# Calculate evaluation metrics
accuracy = accuracy_score(test_labels_encoded, y_pred)
#precision = precision_score(test_labels_encoded, y_pred, average='weighted')
recall = recall_score(test_labels_encoded, y_pred, average='weighted')
f1 = f1_score(test_labels_encoded, y_pred, average='weighted')

print(f'Accuracy: {accuracy}')
#print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1-Score: {f1}')

import cv2
import numpy as np
from tensorflow.keras.models import load_model

# Load the pre-trained MobileNetV2-based CNN model
saved_model_path = '/content/drive/My Drive/Skin Detection Using CNN/mobilenetv2_cnn_model.h3'
model = load_model(saved_model_path)

# Function to preprocess the new image
def preprocess_image(image_path):
    img = cv2.imread(image_path)
    img = cv2.resize(img, (224, 224))  # Resize to match model input shape
    img = img / 255.0  # Normalize pixel values
    return img

# Function to classify the image
def classify_image(image_path):
    # Preprocess the image
    preprocessed_img = preprocess_image(image_path)

    # Reshape the image to match the model input shape
    input_image = np.expand_dims(preprocessed_img, axis=0)

    # Predict the class probabilities
    probabilities = model.predict(input_image)

    # Get the predicted class index
    predicted_class_index = np.argmax(probabilities)

    # Map the class index to the corresponding category
    categories = ['Dry', 'Oily', 'Normal']
    predicted_category = categories[predicted_class_index]

    return predicted_category

# Example usage:
image_path = '/content/drive/My Drive/skin/train/oil15.jpeg'  # Update with the path to your image
predicted_category = classify_image(image_path)
print('Predicted Category:', predicted_category)

from google.colab.patches import cv2_imshow
import cv2
import numpy as np
from tensorflow.keras.models import load_model

# Load the pre-trained MobileNetV2-based CNN model
saved_model_path = '/content/drive/My Drive/Skin Detection Using CNN/mobilenetv2_cnn_model.h3'
model = load_model(saved_model_path)

# Function to preprocess the new image
def preprocess_image(image_path):
    img = cv2.imread(image_path)
    img = cv2.resize(img, (224, 224))  # Resize to match model input shape
    img = img / 255.0  # Normalize pixel values
    return img

# Function to classify the image
def classify_image(image_path):
    # Preprocess the image
    preprocessed_img = preprocess_image(image_path)

    # Reshape the image to match the model input shape
    input_image = np.expand_dims(preprocessed_img, axis=0)

    # Predict the class probabilities
    probabilities = model.predict(input_image)

    # Get the predicted class index
    predicted_class_index = np.argmax(probabilities)

    # Map the class index to the corresponding category
    categories = ['Dry', 'Oily', 'Normal']
    predicted_category = categories[predicted_class_index]

    return predicted_category, preprocessed_img

# Example usage:
image_path = '/content/drive/My Drive/skin/train/dry17.jpeg'  # Update with the path to your image
predicted_category, input_image = classify_image(image_path)
print('Predicted Category:', predicted_category)

from google.colab.patches import cv2_imshow
import cv2
import numpy as np
from tensorflow.keras.models import load_model

# Load the pre-trained MobileNetV2-based CNN model
saved_model_path = '/content/drive/My Drive/Skin Detection Using CNN/mobilenetv2_cnn_model.h3'
model = load_model(saved_model_path)

# Function to preprocess the new image
def preprocess_image(image_path):
    img = cv2.imread(image_path)
    img = cv2.resize(img, (224, 224))  # Resize to match model input shape
    img = img / 255.0  # Normalize pixel values
    return img

# Function to classify the image
def classify_image(image_path):
    # Preprocess the image
    preprocessed_img = preprocess_image(image_path)

    # Reshape the image to match the model input shape
    input_image = np.expand_dims(preprocessed_img, axis=0)

    # Predict the class probabilities
    probabilities = model.predict(input_image)

    # Get the predicted class index
    predicted_class_index = np.argmax(probabilities)

    # Map the class index to the corresponding category
    categories = ['Dry', 'Oily', 'Normal']
    predicted_category = categories[predicted_class_index]

    return predicted_category, preprocessed_img

# Example usage:
image_path = '/content/drive/My drive/skin/test/com5.jpeg'  # Update with the path to your image
predicted_category, input_image = classify_image(image_path)
print('Predicted Category:', predicted_category)